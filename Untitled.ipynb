{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gathering Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "import pandas as pd\n",
    "import time\n",
    "import requests\n",
    "import datetime as dt\n",
    "def get_date(created):\n",
    "    # get the date of post\n",
    "    return dt.date.fromtimestamp(created)\n",
    "def query_pushshift(subreddit, kind='submission', skip=4, times=450, \n",
    "                    subfield = ['title', 'selftext', 'subreddit', 'created_utc', 'author', 'num_comments',\n",
    "                                'score', 'is_self'],\n",
    "                    comfields = ['body', 'score', 'created_utc']):\n",
    "    # get the base url that contains information I want to scrape where 'kind' are all submitted posts\n",
    "    # and 'subreddit' is the specified subreddit. Get 500 posts.\n",
    "    stem = f\"https://api.pushshift.io/reddit/search/{kind}/?subreddit={subreddit}&size=500\"\n",
    "    # instantiate list to contain \n",
    "    mylist = []\n",
    "    # scrape posts from the subreddit 'times' times\n",
    "    for x in range(1, times + 1):\n",
    "        # Get posts 'skip' * 'x' days ago\n",
    "        URL = f\"{stem}&after={skip * x}d\"\n",
    "        print(URL)\n",
    "        # Scrape URL\n",
    "        response = requests.get(URL)\n",
    "        # Give me an AssertionError if status code not 200\n",
    "        assert response.status_code == 200\n",
    "        # Of the HTML scraped, take the values of 'data'\n",
    "        the_json=response.json()\n",
    "        no_blanks=[c for c in the_json['data'] if ('selftext' in c.keys()) and len(c['selftext'])>10]\n",
    "        # turn the data into a dataframe\n",
    "        df = pd.DataFrame.from_dict(no_blanks)\n",
    "        # append the dataframe to mylist\n",
    "        mylist.append(df)\n",
    "        # wait to not overrun Reddit's resources\n",
    "        time.sleep(3)\n",
    "    # concatenate the dataframes together as one large dataframe, full\n",
    "    full = pd.concat(mylist, sort=False)\n",
    "    if kind == \"submission\":\n",
    "        # take all speficied data\n",
    "        full = full[subfield]\n",
    "        # drop duplicate rows\n",
    "        full = full.drop_duplicates()\n",
    "        full = full.loc[full['is_self'] == True]\n",
    "    # date the the post was... posted\n",
    "    _timestamp = full[\"created_utc\"].apply(get_date)\n",
    "    full['timestamp'] = _timestamp\n",
    "    print(full.shape)\n",
    "    return full\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "```python\n",
    "df1 = query_pushshift('artificial')\n",
    "df = query_pushshift('MachineLearning')\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Code above was used to web scrape reddit "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving csv files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1= pd.read_csv('./final1_csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('./final_csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/site-packages/ipykernel_launcher.py:1: FutureWarning: Sorting because non-concatenation axis is not aligned. A future version\n",
      "of pandas will change to not sort by default.\n",
      "\n",
      "To accept the future behavior, pass 'sort=False'.\n",
      "\n",
      "To retain the current behavior and silence the warning, pass 'sort=True'.\n",
      "\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "final = pd.concat([df,df1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Concat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [],
   "source": [
    "final = final[final['author'] != 'AutoModerator']\n",
    "final.drop(columns =['Unnamed: 0','timestamp', 'score', 'is_self','num_comments'], inplace=True)\n",
    "final.to_csv('./final_data_set.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [],
   "source": [
    "final['subreddit'] = final['subreddit'].map({'MachineLearning': 0, 'artificial': 1})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0.1</th>\n",
       "      <th>Unnamed: 0.1.1</th>\n",
       "      <th>author</th>\n",
       "      <th>created_utc</th>\n",
       "      <th>selftext</th>\n",
       "      <th>subreddit</th>\n",
       "      <th>title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>__czyzewski</td>\n",
       "      <td>1579903195</td>\n",
       "      <td>**Project/Source Code:** [https://github.com/m...</td>\n",
       "      <td>0</td>\n",
       "      <td>[R] [P] batchboost: regularization for stabili...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>sculptor311</td>\n",
       "      <td>1579904755</td>\n",
       "      <td>Hallo\\n\\nIch  suche Teilnehmer für meine Umfra...</td>\n",
       "      <td>0</td>\n",
       "      <td>[P] Umfrage bezüglich künstlicher Intelligenz ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ExtremeSavings</td>\n",
       "      <td>1579909752</td>\n",
       "      <td>What is currently considered the state of the ...</td>\n",
       "      <td>0</td>\n",
       "      <td>[D] asynchronous stochastic gradient descent</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>whria78</td>\n",
       "      <td>1579910017</td>\n",
       "      <td>https://journals.plos.org/plosone/article?id=1...</td>\n",
       "      <td>0</td>\n",
       "      <td>[R] Pigeons classify breast cancer as well as ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>insanelylogical</td>\n",
       "      <td>1579915874</td>\n",
       "      <td>A lot of people I have talked to seem to think...</td>\n",
       "      <td>0</td>\n",
       "      <td>[D] Thoughts on why training a network from a ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0.1  Unnamed: 0.1.1           author  created_utc  \\\n",
       "0           NaN             NaN      __czyzewski   1579903195   \n",
       "1           NaN             NaN      sculptor311   1579904755   \n",
       "2           NaN             NaN   ExtremeSavings   1579909752   \n",
       "3           NaN             NaN          whria78   1579910017   \n",
       "4           NaN             NaN  insanelylogical   1579915874   \n",
       "\n",
       "                                            selftext  subreddit  \\\n",
       "0  **Project/Source Code:** [https://github.com/m...          0   \n",
       "1  Hallo\\n\\nIch  suche Teilnehmer für meine Umfra...          0   \n",
       "2  What is currently considered the state of the ...          0   \n",
       "3  https://journals.plos.org/plosone/article?id=1...          0   \n",
       "4  A lot of people I have talked to seem to think...          0   \n",
       "\n",
       "                                               title  \n",
       "0  [R] [P] batchboost: regularization for stabili...  \n",
       "1  [P] Umfrage bezüglich künstlicher Intelligenz ...  \n",
       "2       [D] asynchronous stochastic gradient descent  \n",
       "3  [R] Pigeons classify breast cancer as well as ...  \n",
       "4  [D] Thoughts on why training a network from a ...  "
      ]
     },
     "execution_count": 234,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0.1</th>\n",
       "      <th>Unnamed: 0.1.1</th>\n",
       "      <th>author</th>\n",
       "      <th>created_utc</th>\n",
       "      <th>selftext</th>\n",
       "      <th>subreddit</th>\n",
       "      <th>title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>__czyzewski</td>\n",
       "      <td>1579903195</td>\n",
       "      <td>**Project/Source Code:** [https://github.com/m...</td>\n",
       "      <td>0</td>\n",
       "      <td>[R] [P] batchboost: regularization for stabili...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>sculptor311</td>\n",
       "      <td>1579904755</td>\n",
       "      <td>Hallo\\n\\nIch  suche Teilnehmer für meine Umfra...</td>\n",
       "      <td>0</td>\n",
       "      <td>[P] Umfrage bezüglich künstlicher Intelligenz ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ExtremeSavings</td>\n",
       "      <td>1579909752</td>\n",
       "      <td>What is currently considered the state of the ...</td>\n",
       "      <td>0</td>\n",
       "      <td>[D] asynchronous stochastic gradient descent</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>whria78</td>\n",
       "      <td>1579910017</td>\n",
       "      <td>https://journals.plos.org/plosone/article?id=1...</td>\n",
       "      <td>0</td>\n",
       "      <td>[R] Pigeons classify breast cancer as well as ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>insanelylogical</td>\n",
       "      <td>1579915874</td>\n",
       "      <td>A lot of people I have talked to seem to think...</td>\n",
       "      <td>0</td>\n",
       "      <td>[D] Thoughts on why training a network from a ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5230</th>\n",
       "      <td>5230.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>hampthecoolest</td>\n",
       "      <td>1424881406</td>\n",
       "      <td>I recently have been replaying mega man battle...</td>\n",
       "      <td>1</td>\n",
       "      <td>How many decades until \"Net Navi's\" could be a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5231</th>\n",
       "      <td>5231.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Thistleknot</td>\n",
       "      <td>1424909230</td>\n",
       "      <td>Anyone know any good ones?  Maybe with [pseudo...</td>\n",
       "      <td>1</td>\n",
       "      <td>Recurrent neural network tutorials?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5232</th>\n",
       "      <td>5232.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>kazein</td>\n",
       "      <td>1424914198</td>\n",
       "      <td>-So, I did a quick search and couldn't find an...</td>\n",
       "      <td>1</td>\n",
       "      <td>Scripting computer opponent AI for Star Wars:G...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5233</th>\n",
       "      <td>5233.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>Thistleknot</td>\n",
       "      <td>1425006236</td>\n",
       "      <td>Trying a simple feed forward ANN.\\n\\nI know to...</td>\n",
       "      <td>1</td>\n",
       "      <td>Question on threshold's and weights for an ANN.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5234</th>\n",
       "      <td>5234.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>justonium</td>\n",
       "      <td>1425063423</td>\n",
       "      <td>I am currently working on a computing system w...</td>\n",
       "      <td>1</td>\n",
       "      <td>What computing systems have been built out of ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10678 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Unnamed: 0.1  Unnamed: 0.1.1           author  created_utc  \\\n",
       "0              NaN             NaN      __czyzewski   1579903195   \n",
       "1              NaN             NaN      sculptor311   1579904755   \n",
       "2              NaN             NaN   ExtremeSavings   1579909752   \n",
       "3              NaN             NaN          whria78   1579910017   \n",
       "4              NaN             NaN  insanelylogical   1579915874   \n",
       "...            ...             ...              ...          ...   \n",
       "5230        5230.0             1.0   hampthecoolest   1424881406   \n",
       "5231        5231.0             2.0      Thistleknot   1424909230   \n",
       "5232        5232.0             3.0           kazein   1424914198   \n",
       "5233        5233.0             4.0      Thistleknot   1425006236   \n",
       "5234        5234.0             5.0        justonium   1425063423   \n",
       "\n",
       "                                               selftext  subreddit  \\\n",
       "0     **Project/Source Code:** [https://github.com/m...          0   \n",
       "1     Hallo\\n\\nIch  suche Teilnehmer für meine Umfra...          0   \n",
       "2     What is currently considered the state of the ...          0   \n",
       "3     https://journals.plos.org/plosone/article?id=1...          0   \n",
       "4     A lot of people I have talked to seem to think...          0   \n",
       "...                                                 ...        ...   \n",
       "5230  I recently have been replaying mega man battle...          1   \n",
       "5231  Anyone know any good ones?  Maybe with [pseudo...          1   \n",
       "5232  -So, I did a quick search and couldn't find an...          1   \n",
       "5233  Trying a simple feed forward ANN.\\n\\nI know to...          1   \n",
       "5234  I am currently working on a computing system w...          1   \n",
       "\n",
       "                                                  title  \n",
       "0     [R] [P] batchboost: regularization for stabili...  \n",
       "1     [P] Umfrage bezüglich künstlicher Intelligenz ...  \n",
       "2          [D] asynchronous stochastic gradient descent  \n",
       "3     [R] Pigeons classify breast cancer as well as ...  \n",
       "4     [D] Thoughts on why training a network from a ...  \n",
       "...                                                 ...  \n",
       "5230  How many decades until \"Net Navi's\" could be a...  \n",
       "5231                Recurrent neural network tutorials?  \n",
       "5232  Scripting computer opponent AI for Star Wars:G...  \n",
       "5233    Question on threshold's and weights for an ANN.  \n",
       "5234  What computing systems have been built out of ...  \n",
       "\n",
       "[10678 rows x 7 columns]"
      ]
     },
     "execution_count": 308,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = final['selftext']\n",
    "y = final['subreddit']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X,\n",
    "                                                    y,\n",
    "                                                    test_size=0.33,\n",
    "                                                    stratify=y,\n",
    "                                                    random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import regex as re\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [],
   "source": [
    "lemmatizer = WordNetLemmatizer()\n",
    "p_stemmer = PorterStemmer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_words(raw_review):\n",
    "    # Function to convert a raw review to a string of words\n",
    "    # The input is a single string (a raw movie review), and \n",
    "    # the output is a single string (a preprocessed movie review)\n",
    "    \n",
    "    # 1. Remove HTML.\n",
    "    review_text = BeautifulSoup(raw_review).get_text()\n",
    "    \n",
    "    # 2. Remove non-letters.\n",
    "    letters_only = re.sub(\"[^a-zA-Z]\", \" \", review_text)\n",
    "    \n",
    "    # 3. Convert to lower case, split into individual words.\n",
    "    words = letters_only.lower().split()\n",
    "    \n",
    "    # 4. In Python, searching a set is much faster than searching\n",
    "    # a list, so convert the stop words to a set.\n",
    "    stops = set(stopwords.words('english'))\n",
    "    \n",
    "    # 5. Remove stop words.\n",
    "    meaningful_words = [w for w in words if w not in stops]\n",
    "    lemma_words = [lemmatizer.lemmatize(a) for a in meaningful_words]\n",
    "    stem_words = [p_stemmer.stem(i) for i in lemma_words]\n",
    "    # 6. Join the words back into one string separated by space, \n",
    "    # and return the result.\n",
    "    return(\" \".join(stem_words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conver_str (str_self):\n",
    "    new_machine_self = []\n",
    "    for machine in str_self:\n",
    "        # Convert review to words, then append to clean_train_reviews.\n",
    "        new_machine_self.append(to_words(machine))\n",
    "    return new_machine_self"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3.7/site-packages/bs4/__init__.py:375: UserWarning: \"http://www.theverge.com/2016/5/4/11593564/viv-labs-unveiling-monday-new-ai-from-siri-creators\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "/usr/lib/python3.7/site-packages/bs4/__init__.py:375: UserWarning: \"http://www.techinsider.io/oscar-salazar-on-how-ai-could-revolutionize-the-world-2016-3\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "/usr/lib/python3.7/site-packages/bs4/__init__.py:375: UserWarning: \"http://www.theguardian.com/australia-news/2016/feb/26/future-of-work-remote-controlled-vehicle-operators-in-demand-in-2035\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "/usr/lib/python3.7/site-packages/bs4/__init__.py:375: UserWarning: \"http://www.datasciencecentral.com/profiles/blogs/book-evaluating-machine-learning-models\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "/usr/lib/python3.7/site-packages/bs4/__init__.py:375: UserWarning: \"http://www.theverge.com/2016/3/10/11192774/demis-hassabis-interview-alphago-google-deepmind-ai\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "/usr/lib/python3.7/site-packages/bs4/__init__.py:375: UserWarning: \"http://googlecloudplatform.blogspot.com/2016/02/Google-Cloud-Vision-API-enters-beta-open-to-all-to-try.html?m=1\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "/usr/lib/python3.7/site-packages/bs4/__init__.py:375: UserWarning: \"http://techcrunch.com/2016/02/25/meet-brain-the-ai-engine-that-wants-to-replace-search/\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "/usr/lib/python3.7/site-packages/bs4/__init__.py:375: UserWarning: \"https://medium.com/@rnaresh.n/a-wizards-guide-to-adversarial-autoencoders-part-4-classify-mnist-using-1000-labels-2ca08071f95\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "/usr/lib/python3.7/site-packages/bs4/__init__.py:375: UserWarning: \"https://www.marktechpost.com/2019/10/27/now-you-can-train-an-ai-to-swipe-tinder-for-you-auto-tinder/\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "/usr/lib/python3.7/site-packages/bs4/__init__.py:375: UserWarning: \"http://www.technologyreview.com/news/545486/chinas-baidu-releases-its-ai-code/\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "/usr/lib/python3.7/site-packages/bs4/__init__.py:375: UserWarning: \"http://www.somatic.io/blog/real-competition-in-the-deep-learning-hardware-space\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "/usr/lib/python3.7/site-packages/bs4/__init__.py:375: UserWarning: \"https://www.outsideonline.com/2407822/artificial-intelligence-running-form-study\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "/usr/lib/python3.7/site-packages/bs4/__init__.py:375: UserWarning: \"http://techcrunch.com/2016/03/19/msg-ais-puneet-mehta-on-the-rise-of-ai-the-potential-for-bots-and-life-as-a-current-yc-startup/\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "/usr/lib/python3.7/site-packages/bs4/__init__.py:375: UserWarning: \"http://www.theverge.com/2016/3/10/11187816/neuraltalk-ai-scry-app\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "/usr/lib/python3.7/site-packages/bs4/__init__.py:375: UserWarning: \"http://www.datasciencecentral.com/profiles/blogs/a-curated-list-of-resources-dedicated-to-bayesian-deep-learning\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "/usr/lib/python3.7/site-packages/bs4/__init__.py:375: UserWarning: \"https://link.medium.com/OWCZFkp9fZ\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "/usr/lib/python3.7/site-packages/bs4/__init__.py:375: UserWarning: \"http://m.nautil.us/issue/33/attraction/your-next-new-best-friend-might-be-a-robot\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "/usr/lib/python3.7/site-packages/bs4/__init__.py:375: UserWarning: \"http://www.businessinsider.com/evernote-founder-phil-libin-creating-incubator-for-bots-2016-3?r=UK&amp;IR=T\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "/usr/lib/python3.7/site-packages/bs4/__init__.py:375: UserWarning: \"http://www.datasciencecentral.com/profiles/blogs/two-great-courses-on-deep-learning-and-ai\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "/usr/lib/python3.7/site-packages/bs4/__init__.py:375: UserWarning: \"https://en.m.wikipedia.org/wiki/Vanishing_gradient_problem\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "/usr/lib/python3.7/site-packages/bs4/__init__.py:375: UserWarning: \"http://www.theverge.com/2016/3/1/11136298/hound-app-ios-android-siri-google-now-cortana\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3.7/site-packages/bs4/__init__.py:375: UserWarning: \"http://m.huffpost.com/us/entry/artificial-intelligence-mit-tech-conference_us_56cb20ade4b0928f5a6c7463\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "/usr/lib/python3.7/site-packages/bs4/__init__.py:375: UserWarning: \"http://www.datasciencecentral.com/profiles/blogs/factoring-massive-numbers-a-new-machine-learning-approach\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "/usr/lib/python3.7/site-packages/bs4/__init__.py:375: UserWarning: \"https://technomosis.blog/2019/03/30/nvidias-ai-software-converts-drawings-into-photo-realistic-landscapes/\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "/usr/lib/python3.7/site-packages/bs4/__init__.py:375: UserWarning: \"https://github.com/BrianSantoso/SketchGAN\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "/usr/lib/python3.7/site-packages/bs4/__init__.py:375: UserWarning: \"http://www.technologyreview.com/view/545316/ai-algorithm-identifies-humorous-pictures/\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "/usr/lib/python3.7/site-packages/bs4/__init__.py:375: UserWarning: \"http://gizmodo.com/everything-you-know-about-artificial-intelligence-is-wr-1764020220\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "/usr/lib/python3.7/site-packages/bs4/__init__.py:375: UserWarning: \"https://github.com/rowanz/grover\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "/usr/lib/python3.7/site-packages/bs4/__init__.py:375: UserWarning: \"http://mobile.nytimes.com/2016/02/29/technology/the-promise-of-artificial-intelligence-unfolds-in-small-steps.html?referer=android-app://com.google.android.googlequicksearchbox/https/www.google.com\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "/usr/lib/python3.7/site-packages/bs4/__init__.py:375: UserWarning: \"https://www.datasciencecentral.com/profiles/blogs/programming-languages-for-data-science-and-ml-with-source-code-il\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "/usr/lib/python3.7/site-packages/bs4/__init__.py:375: UserWarning: \"http://www.example.org/ex-link-test\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "/usr/lib/python3.7/site-packages/bs4/__init__.py:375: UserWarning: \"https://thestack.com/cloud/2016/02/11/why-sarcasm-is-such-a-problem-in-artificial-intelligence/\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "/usr/lib/python3.7/site-packages/bs4/__init__.py:375: UserWarning: \"http://www.datasciencecentral.com/profiles/blogs/top-10-ipython-tutorials-for-data-science-and-machine-learning\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "/usr/lib/python3.7/site-packages/bs4/__init__.py:375: UserWarning: \"https://np.reddit.com/r/magicTCG/comments/3hj577/i_wrote_a_genetic_algorithm_that_attempts_to_find/\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "/usr/lib/python3.7/site-packages/bs4/__init__.py:375: UserWarning: \"http://www.wired.com/2016/02/googles-artificial-intelligence-gets-first-art-show/\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "/usr/lib/python3.7/site-packages/bs4/__init__.py:375: UserWarning: \"https://www.producthunt.com/tech/summize\n",
      "\n",
      "https://itunes.apple.com/us/app/summize/id1087195099?mt=8\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "/usr/lib/python3.7/site-packages/bs4/__init__.py:375: UserWarning: \"http://www.engadget.com/2016/02/07/low-power-neural-network-chip/\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "/usr/lib/python3.7/site-packages/bs4/__init__.py:375: UserWarning: \"http://stats.stackexchange.com/questions/183513/implicit-feature-space-of-power-kernel\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "/usr/lib/python3.7/site-packages/bs4/__init__.py:375: UserWarning: \"https://www.datasciencecentral.com/profiles/blogs/deep-learning-alphago-zero-explained-in-one-picture\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "/usr/lib/python3.7/site-packages/bs4/__init__.py:375: UserWarning: \"https://futurism.com/google-artificial-intelligence-built-ai/\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "/usr/lib/python3.7/site-packages/bs4/__init__.py:375: UserWarning: \"https://techcrunch.com/2019/12/11/arthur-announces-3-3m-seed-to-monitor-machine-learning-model-performance/\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "/usr/lib/python3.7/site-packages/bs4/__init__.py:375: UserWarning: \"https://stackoverflow.com/questions/59882845/get-lr-from-cyclical-learning-rate-in-pytorch\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "/usr/lib/python3.7/site-packages/bs4/__init__.py:375: UserWarning: \"http://www.wired.com/2016/02/well-know-soon-if-google-can-beat-a-super-grandmaster-at-go/\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3.7/site-packages/bs4/__init__.py:375: UserWarning: \"http://www.engadget.com/2016/02/17/xprize-ibm-ai/\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "/usr/lib/python3.7/site-packages/bs4/__init__.py:375: UserWarning: \"http://venturebeat.com/2016/03/18/bots-are-big-this-ai-startup-can-turn-slack-into-smarterchild-on-steroids/\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "/usr/lib/python3.7/site-packages/bs4/__init__.py:375: UserWarning: \"https://www.mercurynews.com/2019/12/05/how-artificial-intelligence-is-helping-spot-california-wildfires-faster/\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "/usr/lib/python3.7/site-packages/bs4/__init__.py:375: UserWarning: \"http://www.wired.com/2016/01/the-rise-of-the-artificially-intelligent-hedge-fund/\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "/usr/lib/python3.7/site-packages/bs4/__init__.py:375: UserWarning: \"http://www.engadget.com/2016/03/18/dominos-autonomous-pizza-delivery-vehicle/\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "/usr/lib/python3.7/site-packages/bs4/__init__.py:375: UserWarning: \"http://www.engadget.com/2016/02/28/ai-learns-to-predict-human-reactions-by-reading-our-fiction/\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "/usr/lib/python3.7/site-packages/bs4/__init__.py:375: UserWarning: \"http://money.cnn.com/2016/02/22/technology/google-brain-artificial-intelligence-quoc-le/\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "/usr/lib/python3.7/site-packages/bs4/__init__.py:375: UserWarning: \"https://i.redd.it/jfmydy0e3rd11.png\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "/usr/lib/python3.7/site-packages/bs4/__init__.py:375: UserWarning: \"http://www.mirror.co.uk/tech/would-you-eat-restaurant-robot-7576240\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "/usr/lib/python3.7/site-packages/bs4/__init__.py:375: UserWarning: \"https://slideslive.com/icml\n",
      "https://facebook.com/pg/icml.imls/videos/\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "/usr/lib/python3.7/site-packages/bs4/__init__.py:375: UserWarning: \"http://qz.com/624838/to-be-more-like-us-facebooks-ai-is-reading-itself-classic-childrens-books/\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "/usr/lib/python3.7/site-packages/bs4/__init__.py:375: UserWarning: \"https://www.reddit.com/r/ludobots/comments/3gw70s/ludobots_happy_one_year_anniversary/\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "/usr/lib/python3.7/site-packages/bs4/__init__.py:375: UserWarning: \"http://www.fastcompany.com/3056018/exclusive-inside-facebooks-ai-hackathon\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "/usr/lib/python3.7/site-packages/bs4/__init__.py:375: UserWarning: \"https://www.datasciencecentral.com/profiles/blogs/machine-learning-in-finance-why-what-amp-how\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "/usr/lib/python3.7/site-packages/bs4/__init__.py:375: UserWarning: \"http://www.theguardian.com/technology/2016/mar/03/artificial-intelligence-hackers-security-autonomous-learning\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "/usr/lib/python3.7/site-packages/bs4/__init__.py:375: UserWarning: \"https://www.newscientist.com/article/2078074-ai-solves-100-hat-puzzle-used-in-google-job-interviews/\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "/usr/lib/python3.7/site-packages/bs4/__init__.py:375: UserWarning: \"http://www.wired.com/2016/03/googles-ai-wins-first-game-historic-match-go-champion/\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "/usr/lib/python3.7/site-packages/bs4/__init__.py:375: UserWarning: \"http://www.theverge.com/2016/4/25/11492102/bill-gates-interview-education-software-artificial-intelligence\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "/usr/lib/python3.7/site-packages/bs4/__init__.py:375: UserWarning: \"https://www.etftrends.com/innovative-etfs-channel/starbucks-looking-to-utilize-artificial-intelligence-ai-technology/\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "/usr/lib/python3.7/site-packages/bs4/__init__.py:375: UserWarning: \"https://arxiv.org/abs/1911.02116\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "/usr/lib/python3.7/site-packages/bs4/__init__.py:375: UserWarning: \"http://www.theverge.com/2016/2/26/11120274/ibm-watson-commercial-carrie-fisher-steve-buscemi\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3.7/site-packages/bs4/__init__.py:375: UserWarning: \"http://www.datasciencecentral.com/profiles/blogs/machine-learning-the-bigger-picture-part-i\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "/usr/lib/python3.7/site-packages/bs4/__init__.py:375: UserWarning: \"http://www.engadget.com/2016/02/23/ibm-watson-sword-art-online-vrmmo/\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "/usr/lib/python3.7/site-packages/bs4/__init__.py:375: UserWarning: \"https://www.datasciencecentral.com/profiles/blogs/which-machine-learning-algo-will-continue-to-be-in-use-in-year\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "/usr/lib/python3.7/site-packages/bs4/__init__.py:375: UserWarning: \"http://www.techinsider.io/13-ai-researchers-talk-facts-blow-minds-2016-2\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n"
     ]
    }
   ],
   "source": [
    "X_train = conver_str(X_train)\n",
    "X_test = conver_str(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ai</th>\n",
       "      <th>com</th>\n",
       "      <th>data</th>\n",
       "      <th>github</th>\n",
       "      <th>http</th>\n",
       "      <th>human</th>\n",
       "      <th>intellig</th>\n",
       "      <th>know</th>\n",
       "      <th>learn</th>\n",
       "      <th>like</th>\n",
       "      <th>machin</th>\n",
       "      <th>model</th>\n",
       "      <th>one</th>\n",
       "      <th>think</th>\n",
       "      <th>time</th>\n",
       "      <th>train</th>\n",
       "      <th>use</th>\n",
       "      <th>work</th>\n",
       "      <th>would</th>\n",
       "      <th>www</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.340121</td>\n",
       "      <td>0.342212</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.581524</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.494942</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.429035</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.226506</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.180845</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.230638</td>\n",
       "      <td>0.455168</td>\n",
       "      <td>0.221728</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.726740</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.207505</td>\n",
       "      <td>0.187738</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.450791</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.726720</td>\n",
       "      <td>0.518330</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.637934</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.547324</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.541735</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.269928</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.458690</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.552026</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.527413</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.365849</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7149</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.239817</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.362325</td>\n",
       "      <td>0.203761</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.149888</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.617202</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.492726</td>\n",
       "      <td>0.351435</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7150</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.470707</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.399938</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.459858</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.637977</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7151</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.499716</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.754991</td>\n",
       "      <td>0.424585</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7152</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.539751</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.397043</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.310309</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.674340</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7153</th>\n",
       "      <td>0.491246</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.374523</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.617844</td>\n",
       "      <td>0.252705</td>\n",
       "      <td>0.265043</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.320267</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7154 rows × 20 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            ai       com      data    github      http     human  intellig  \\\n",
       "0     0.340121  0.342212  0.000000  0.000000  0.581524  0.000000  0.494942   \n",
       "1     0.000000  0.000000  0.226506  0.000000  0.000000  0.000000  0.000000   \n",
       "2     0.000000  0.000000  0.000000  0.000000  0.450791  0.000000  0.000000   \n",
       "3     0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "4     0.000000  0.269928  0.000000  0.000000  0.458690  0.000000  0.000000   \n",
       "...        ...       ...       ...       ...       ...       ...       ...   \n",
       "7149  0.000000  0.239817  0.000000  0.362325  0.203761  0.000000  0.000000   \n",
       "7150  0.000000  0.470707  0.000000  0.000000  0.399938  0.000000  0.000000   \n",
       "7151  0.000000  0.499716  0.000000  0.754991  0.424585  0.000000  0.000000   \n",
       "7152  0.000000  0.000000  0.000000  0.000000  0.539751  0.000000  0.000000   \n",
       "7153  0.491246  0.000000  0.000000  0.000000  0.000000  0.374523  0.000000   \n",
       "\n",
       "          know     learn      like    machin     model       one     think  \\\n",
       "0     0.000000  0.000000  0.000000  0.000000  0.000000  0.429035  0.000000   \n",
       "1     0.000000  0.180845  0.000000  0.230638  0.455168  0.221728  0.000000   \n",
       "2     0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "3     0.637934  0.000000  0.547324  0.000000  0.000000  0.000000  0.000000   \n",
       "4     0.000000  0.552026  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "...        ...       ...       ...       ...       ...       ...       ...   \n",
       "7149  0.149888  0.000000  0.000000  0.000000  0.617202  0.000000  0.000000   \n",
       "7150  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "7151  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "7152  0.397043  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "7153  0.617844  0.252705  0.265043  0.000000  0.000000  0.000000  0.320267   \n",
       "\n",
       "      time     train       use      work     would       www  \n",
       "0      0.0  0.000000  0.000000  0.000000  0.000000  0.000000  \n",
       "1      0.0  0.726740  0.000000  0.207505  0.187738  0.000000  \n",
       "2      0.0  0.726720  0.518330  0.000000  0.000000  0.000000  \n",
       "3      0.0  0.000000  0.000000  0.000000  0.541735  0.000000  \n",
       "4      0.0  0.000000  0.527413  0.000000  0.000000  0.365849  \n",
       "...    ...       ...       ...       ...       ...       ...  \n",
       "7149   0.0  0.492726  0.351435  0.000000  0.000000  0.000000  \n",
       "7150   0.0  0.000000  0.459858  0.000000  0.000000  0.637977  \n",
       "7151   0.0  0.000000  0.000000  0.000000  0.000000  0.000000  \n",
       "7152   0.0  0.000000  0.310309  0.000000  0.674340  0.000000  \n",
       "7153   0.0  0.000000  0.000000  0.000000  0.000000  0.000000  \n",
       "\n",
       "[7154 rows x 20 columns]"
      ]
     },
     "execution_count": 312,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vect = TfidfVectorizer(max_features=20)\n",
    "tfidf_matrix = vect.fit_transform(X_train)\n",
    "dfr = pd.DataFrame(tfidf_matrix.toarray(), columns = vect.get_feature_names())\n",
    "dfr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ai</th>\n",
       "      <th>com</th>\n",
       "      <th>data</th>\n",
       "      <th>github</th>\n",
       "      <th>http</th>\n",
       "      <th>human</th>\n",
       "      <th>intellig</th>\n",
       "      <th>know</th>\n",
       "      <th>learn</th>\n",
       "      <th>like</th>\n",
       "      <th>machin</th>\n",
       "      <th>model</th>\n",
       "      <th>one</th>\n",
       "      <th>think</th>\n",
       "      <th>time</th>\n",
       "      <th>train</th>\n",
       "      <th>use</th>\n",
       "      <th>work</th>\n",
       "      <th>would</th>\n",
       "      <th>www</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7149</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7150</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7151</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7152</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7153</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7154 rows × 20 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      ai  com  data  github  http  human  intellig  know  learn  like  machin  \\\n",
       "0      1    1     0       0     2      0         1     0      0     0       0   \n",
       "1      0    0     1       0     0      0         0     0      1     0       1   \n",
       "2      0    0     0       0     1      0         0     0      0     0       0   \n",
       "3      0    0     0       0     0      0         0     1      0     1       0   \n",
       "4      0    1     0       0     2      0         0     0      2     0       0   \n",
       "...   ..  ...   ...     ...   ...    ...       ...   ...    ...   ...     ...   \n",
       "7149   0    2     0       2     2      0         0     1      0     0       0   \n",
       "7150   0    1     0       0     1      0         0     0      0     0       0   \n",
       "7151   0    2     0       2     2      0         0     0      0     0       0   \n",
       "7152   0    0     0       0     2      0         0     1      0     0       0   \n",
       "7153   2    0     0       0     0      1         0     2      1     1       0   \n",
       "\n",
       "      model  one  think  time  train  use  work  would  www  \n",
       "0         0    1      0     0      0    0     0      0    0  \n",
       "1         2    1      0     0      3    0     1      1    0  \n",
       "2         0    0      0     0      1    1     0      0    0  \n",
       "3         0    0      0     0      0    0     0      1    0  \n",
       "4         0    0      0     0      0    2     0      0    1  \n",
       "...     ...  ...    ...   ...    ...  ...   ...    ...  ...  \n",
       "7149      4    0      0     0      3    3     0      0    0  \n",
       "7150      0    0      0     0      0    1     0      0    1  \n",
       "7151      0    0      0     0      0    0     0      0    0  \n",
       "7152      0    0      0     0      0    1     0      2    0  \n",
       "7153      0    0      1     0      0    0     0      0    0  \n",
       "\n",
       "[7154 rows x 20 columns]"
      ]
     },
     "execution_count": 313,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coun = CountVectorizer(max_features=20)\n",
    "coun_matrix = coun.fit_transform(X_train)\n",
    "dfc = pd.DataFrame(coun_matrix.toarray(), columns = coun.get_feature_names())\n",
    "dfc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modeling "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe = Pipeline([\n",
    "    ('cvec', CountVectorizer()),\n",
    "    ('lr', LogisticRegression(max_iter = 500))\n",
    "])\n",
    "pipe_params = {\n",
    "    'cvec__max_features': [2500, 3000, 3500],\n",
    "    'cvec__min_df': [2, 3],\n",
    "    'cvec__max_df': [.9, .95],\n",
    "    'cvec__ngram_range': [(1,1), (1,2)]\n",
    "}\n",
    "gs = GridSearchCV(pipe, \n",
    "                  param_grid=pipe_params, \n",
    "                  cv=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [],
   "source": [
    "gs.fit(X_train, y_train);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0.509648\n",
       "1    0.490352\n",
       "Name: subreddit, dtype: float64"
      ]
     },
     "execution_count": 245,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test.value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train score: 0.961839530332681\n",
      "Test score: 0.8090238365493757\n"
     ]
    }
   ],
   "source": [
    "print(f\"Train score: {gs.score(X_train, y_train)}\")\n",
    "print(f\"Test score: {gs.score(X_test, y_test)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "best_cvec_logi = gs.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe = Pipeline([\n",
    "    ('tvec', TfidfVectorizer()),\n",
    "    ('lr', LogisticRegression(max_iter = 500))\n",
    "])\n",
    "pipe_params = {\n",
    "    'tvec__max_features': [2500, 3000, 3500],\n",
    "    'tvec__min_df': [2, 3],\n",
    "    'tvec__max_df': [.9, .95],\n",
    "    'tvec__ngram_range': [(1,1), (1,2)]\n",
    "}\n",
    "gs_tvec = GridSearchCV(pipe, \n",
    "                  param_grid=pipe_params, \n",
    "                  cv=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score=nan,\n",
       "             estimator=Pipeline(memory=None,\n",
       "                                steps=[('tvec',\n",
       "                                        TfidfVectorizer(analyzer='word',\n",
       "                                                        binary=False,\n",
       "                                                        decode_error='strict',\n",
       "                                                        dtype=<class 'numpy.float64'>,\n",
       "                                                        encoding='utf-8',\n",
       "                                                        input='content',\n",
       "                                                        lowercase=True,\n",
       "                                                        max_df=1.0,\n",
       "                                                        max_features=None,\n",
       "                                                        min_df=1,\n",
       "                                                        ngram_range=(1, 1),\n",
       "                                                        norm='l2',\n",
       "                                                        preprocessor=None,\n",
       "                                                        smooth_idf=True,\n",
       "                                                        stop_words=None,\n",
       "                                                        strip_acce...\n",
       "                                                           n_jobs=None,\n",
       "                                                           penalty='l2',\n",
       "                                                           random_state=None,\n",
       "                                                           solver='lbfgs',\n",
       "                                                           tol=0.0001,\n",
       "                                                           verbose=0,\n",
       "                                                           warm_start=False))],\n",
       "                                verbose=False),\n",
       "             iid='deprecated', n_jobs=None,\n",
       "             param_grid={'tvec__max_df': [0.9, 0.95],\n",
       "                         'tvec__max_features': [2500, 3000, 3500],\n",
       "                         'tvec__min_df': [2, 3],\n",
       "                         'tvec__ngram_range': [(1, 1), (1, 2)]},\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
       "             scoring=None, verbose=0)"
      ]
     },
     "execution_count": 249,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs_tvec.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8342203847864227\n"
     ]
    }
   ],
   "source": [
    "print(gs_tvec.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train score: 0.8860777187587364\n",
      "Test score: 0.8433598183881952\n"
     ]
    }
   ],
   "source": [
    "print(f\"Train score: {gs_tvec.score(X_train, y_train)}\")\n",
    "print(f\"Test score: {gs_tvec.score(X_test, y_test)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB, GaussianNB, BernoulliNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe_ve = Pipeline([\n",
    "                 ('tvec', TfidfVectorizer()),\n",
    "                 ('mul', MultinomialNB())\n",
    "])\n",
    "\n",
    "pipe_params_mul_ve = {\n",
    "    'tvec__max_features': [2500, 3000, 3500],\n",
    "    'tvec__min_df': [2, 3],\n",
    "    'tvec__max_df': [.9, .95],\n",
    "    'tvec__ngram_range': [(1,1), (1,2)]\n",
    "}\n",
    "mul_ve = GridSearchCV(pipe_ve, \n",
    "                  param_grid=pipe_params_mul_ve, \n",
    "                  cv=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train score: 0.8419066256639642\n",
      "Test score: 0.8095913734392736\n"
     ]
    }
   ],
   "source": [
    "mul_ve.fit(X_train,y_train);\n",
    "print(f\"Train score: {mul_ve.score(X_train, y_train)}\")\n",
    "print(f\"Test score: {mul_ve.score(X_test, y_test)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8214984623986581\n",
      "0.8030646992054483\n"
     ]
    }
   ],
   "source": [
    "pipe_ber_t = Pipeline([\n",
    "                 ('tvec', TfidfVectorizer()),\n",
    "                 ('ber', BernoulliNB())\n",
    "])\n",
    "\n",
    "pipe_params_mul_ber_t = {\n",
    "    'tvec__max_features': [2500, 3000, 3500],\n",
    "    'tvec__min_df': [2, 3],\n",
    "    'tvec__max_df': [.9, .95],\n",
    "    'tvec__ngram_range': [(1,1), (1,2)]\n",
    "}\n",
    "ber_tvec = GridSearchCV(pipe_ber_t, \n",
    "                  param_grid=pipe_params_mul_ber_t, \n",
    "                  cv=5)\n",
    "ber_tvec.fit(X_train, y_train)\n",
    "print(ber_tvec.score(X_train, y_train))\n",
    "print(ber_tvec.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8214984623986581\n",
      "0.8030646992054483\n"
     ]
    }
   ],
   "source": [
    "pipe_ber = Pipeline([\n",
    "                 ('cvec', CountVectorizer()),\n",
    "                 ('ber', BernoulliNB())\n",
    "])\n",
    "\n",
    "pipe_params_mul_ber = {\n",
    "    'cvec__max_features': [2500, 3000, 3500],\n",
    "    'cvec__min_df': [2, 3],\n",
    "    'cvec__max_df': [.9, .95],\n",
    "    'cvec__ngram_range': [(1,1), (1,2)]\n",
    "}\n",
    "ber_cvec = GridSearchCV(pipe_ber, \n",
    "                  param_grid=pipe_params_mul_ber, \n",
    "                  cv=5)\n",
    "ber_cvec.fit(X_train, y_train)\n",
    "print(ber_cvec.score(X_train, y_train))\n",
    "print(ber_cvec.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe_c = Pipeline([\n",
    "                 ('cvec', CountVectorizer()),\n",
    "                 ('mul', MultinomialNB())\n",
    "])\n",
    "\n",
    "pipe_params_mul_cvec = {\n",
    "    'cvec__max_features': [2500, 3000, 3500],\n",
    "    'cvec__min_df': [2, 3],\n",
    "    'cvec__max_df': [.9, .95],\n",
    "    'cvec__ngram_range': [(1,1), (1,2)]\n",
    "}\n",
    "mul_cvec = GridSearchCV(pipe_c, \n",
    "                  param_grid=pipe_params_mul_cvec, \n",
    "                  cv=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score=nan,\n",
       "             estimator=Pipeline(memory=None,\n",
       "                                steps=[('cvec',\n",
       "                                        CountVectorizer(analyzer='word',\n",
       "                                                        binary=False,\n",
       "                                                        decode_error='strict',\n",
       "                                                        dtype=<class 'numpy.int64'>,\n",
       "                                                        encoding='utf-8',\n",
       "                                                        input='content',\n",
       "                                                        lowercase=True,\n",
       "                                                        max_df=1.0,\n",
       "                                                        max_features=None,\n",
       "                                                        min_df=1,\n",
       "                                                        ngram_range=(1, 1),\n",
       "                                                        preprocessor=None,\n",
       "                                                        stop_words=None,\n",
       "                                                        strip_accents=None,\n",
       "                                                        token_pattern='(?u)...\n",
       "                                                        tokenizer=None,\n",
       "                                                        vocabulary=None)),\n",
       "                                       ('mul',\n",
       "                                        MultinomialNB(alpha=1.0,\n",
       "                                                      class_prior=None,\n",
       "                                                      fit_prior=True))],\n",
       "                                verbose=False),\n",
       "             iid='deprecated', n_jobs=None,\n",
       "             param_grid={'cvec__max_df': [0.9, 0.95],\n",
       "                         'cvec__max_features': [2500, 3000, 3500],\n",
       "                         'cvec__min_df': [2, 3],\n",
       "                         'cvec__ngram_range': [(1, 1), (1, 2)]},\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
       "             scoring=None, verbose=0)"
      ]
     },
     "execution_count": 256,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mul_cvec.fit(X_train,y_train);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "         steps=[('cvec',\n",
       "                 CountVectorizer(analyzer='word', binary=False,\n",
       "                                 decode_error='strict',\n",
       "                                 dtype=<class 'numpy.int64'>, encoding='utf-8',\n",
       "                                 input='content', lowercase=True, max_df=0.9,\n",
       "                                 max_features=3500, min_df=3,\n",
       "                                 ngram_range=(1, 1), preprocessor=None,\n",
       "                                 stop_words=None, strip_accents=None,\n",
       "                                 token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       "                                 tokenizer=None, vocabulary=None)),\n",
       "                ('mul',\n",
       "                 MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True))],\n",
       "         verbose=False)"
      ]
     },
     "execution_count": 257,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mul_cvec.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train score: 0.8247134470226447\n",
      "Test score: 0.804483541430193\n"
     ]
    }
   ],
   "source": [
    "print(f\"Train score: {mul_cvec.score(X_train, y_train)}\")\n",
    "print(f\"Test score: {mul_cvec.score(X_test, y_test)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import FunctionTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8160469667318982\n",
      "0.7829171396140749\n"
     ]
    }
   ],
   "source": [
    "tf_ = TfidfVectorizer(max_features=1800, max_df=.95, ngram_range=(1,2), min_df=2)\n",
    "tf_.fit(X_train, y_train)\n",
    "X_train_tf = tf_.transform(X_train).todense()\n",
    "X_test_tf = tf_.transform(X_test).todense()\n",
    "\n",
    "gnb = GaussianNB()\n",
    "\n",
    "gnb.fit(X_train_tf, y_train)\n",
    "print(gnb.score(X_train_tf, y_train))\n",
    "print(gnb.score(X_test_tf, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8331003634330445\n",
      "0.7735527809307605\n"
     ]
    }
   ],
   "source": [
    "pipe_tree = Pipeline([\n",
    "                 ('cvec', CountVectorizer()),\n",
    "                 ('dt', DecisionTreeClassifier(random_state = 42))\n",
    "])\n",
    "pipe_params_tree = {\n",
    "    'cvec__max_features': [2500, 3000, 3500],\n",
    "    'cvec__min_df': [2, 3],\n",
    "    'cvec__max_df': [.9, .95],\n",
    "    'cvec__ngram_range': [(1,1), (1,2)],\n",
    "    'dt__max_depth': [10],\n",
    "    'dt__min_samples_split': [5,7],\n",
    "    'dt__min_samples_leaf': [2,3,4]\n",
    "}\n",
    "tree_cvec = GridSearchCV(pipe_tree, \n",
    "                  param_grid=pipe_params_tree, \n",
    "                  cv=5)\n",
    "tree_cvec.fit(X_train, y_train)\n",
    "print(tree_cvec.score(X_train, y_train))\n",
    "print(tree_cvec.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8381325132792843\n",
      "0.771566401816118\n"
     ]
    }
   ],
   "source": [
    "pipe_tree_tvec = Pipeline([\n",
    "                 ('tvec', TfidfVectorizer()),\n",
    "                 ('dt', DecisionTreeClassifier(random_state = 42))\n",
    "])\n",
    "pipe_params_tree_tvec = {\n",
    "    'tvec__max_features': [3000, 3500],\n",
    "    'tvec__min_df': [2, 3],\n",
    "    'tvec__max_df': [.9, .95],\n",
    "    'tvec__ngram_range': [(1,1), (1,2)],\n",
    "    'dt__max_depth': [10,15,20],\n",
    "    'dt__min_samples_split': [3,5],\n",
    "    'dt__min_samples_leaf': [2,3,4]\n",
    "}\n",
    "tree_tvec = GridSearchCV(pipe_tree_tvec, \n",
    "                  param_grid=pipe_params_tree_tvec, \n",
    "                  cv=5)\n",
    "tree_tvec.fit(X_train, y_train)\n",
    "print(tree_tvec.score(X_train, y_train))\n",
    "print(tree_tvec.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'dt__max_depth': 10,\n",
       " 'dt__min_samples_leaf': 2,\n",
       " 'dt__min_samples_split': 5,\n",
       " 'tvec__max_df': 0.9,\n",
       " 'tvec__max_features': 3000,\n",
       " 'tvec__min_df': 2,\n",
       " 'tvec__ngram_range': (1, 1)}"
      ]
     },
     "execution_count": 305,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tree_tvec.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'dt__max_depth': 10,\n",
       " 'dt__min_samples_leaf': 2,\n",
       " 'dt__min_samples_split': 3,\n",
       " 'tvec__max_df': 0.9,\n",
       " 'tvec__max_features': 3000,\n",
       " 'tvec__min_df': 2,\n",
       " 'tvec__ngram_range': (1, 1)}"
      ]
     },
     "execution_count": 307,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tree_tvec.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 325,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier, ExtraTreesClassifier\n",
    "from sklearn.model_selection import cross_val_score, train_test_split, GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9967850153760134\n",
      "0.837116912599319\n"
     ]
    }
   ],
   "source": [
    "pipe_tree_tvec_r = Pipeline([\n",
    "                 ('tvec', TfidfVectorizer()),\n",
    "                 ('rf', RandomForestClassifier(random_state = 42))\n",
    "])\n",
    "rf_params = {\n",
    "    'tvec__max_features': [3000, 3500],\n",
    "    'tvec__min_df': [2, 3],\n",
    "    'tvec__max_df': [.9, .95],\n",
    "    'tvec__ngram_range': [(1,1), (1,2)],\n",
    "    'rf__n_estimators': [100, 150, 200],\n",
    "    'rf__max_depth': [None, 1, 2, 3, 4, 5],\n",
    "}\n",
    "gs_dr = GridSearchCV(pipe_tree_tvec_r, param_grid=rf_params, cv=5)\n",
    "gs_dr.fit(X_train, y_train)\n",
    "print(gs_dr.score(X_train, y_train))\n",
    "print(gs_dr.score(X_test, y_test))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
